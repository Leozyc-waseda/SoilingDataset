/* -*- mode: C;-*- */
%{
/*
   LoBaylogParser.l -- parsing Bayesian TTI prediction experiments log files

   This file defines various rules for parsing the metrics logs collected
   during the experiments designed to gauge the Bayesian time-to-impact
   prediction model used by Robolocust's TTI algorithm for LGMD-based
   obstacle avoidance.

   Since these log files are fairly straightforward to parse, we don't
   really need a grammar and, therefore, yacc/bison. lex alone will do a
   fine job. That's why this "lexical analyzer" is referred to as a
   "parser." In fact, this lexer really is a parser because it isn't
   concerned with tokenization; instead, it simply looks for certain
   patterns in the input and immediately takes appropriate action to
   parse that input.

   NOTE: This parser is designed specifically for the metlog files spit
   out by the Bayesian TTI prediction experiments concerned with
   measuring the performance of the time-to-impact state estimator used
   by the TTI algorithm for LGMD-based obstacle avoidance. It won't work
   with arbitrary metlog files.
*/

// Primary maintainer for this file: mviswana usc edu
// $HeadURL: svn://isvn.usc.edu/software/invt/trunk/saliency/src/Robots/LoBot/baylog/LoBaylogParser.l $
// $Id: LoBaylogParser.l 14083 2010-09-30 13:59:37Z mviswana $

// lobot headers
#include "Robots/LoBot/baylog/LoTTIMap.H"
#include "Robots/LoBot/util/LoString.H"

// In the code generated by flex, the yy_get_next_buffer() function
// performs a comparison between a signed and unsigned variable. This
// produces a compiler warning, which results in an error because, by
// default, INVT builds are setup to treat all warnings as errors. Since
// we really can't fix the code generated by flex, we resort to turning
// off this warning so that the .C file generated from this Lex source
// builds without any hassles.
//
// DEVNOTE: On Debian etch, which has GCC 4.1.2, this works fine because,
// apparently, the compiler does not care for the signed-unsigned match
// in yy_get_next_buffer().
//
// On Debian lenny, which comes with GCC 4.3.2, and on Ubuntu 10.04LTS
// (Lucid Lynx), which comes with GCC 4.4.3, the diagnostic pragma is
// supported. Thus, we test for at least version 4.3 of GCC.
//
// This may not work on other systems with other versions of GCC. An
// alternative workaround is not known for this particular problem.
#if __GNUC__ >= 4 && __GNUC_MINOR__ >= 3
#pragma GCC diagnostic ignored "-Wsign-compare"
#endif

// The lobot::BaylogAnalyzer object, which is responsible for loading and
// parsing the log files generated during the Bayesian TTI prediction
// experiments, uses this lex-generated scanner for the desired parsing
// functionality. The parsing results are stored in an instance of the
// lobot::TTIMap class. The analyzer object has to create the TTIMap that
// will receive parsing results and pass it to this scanner module using
// flex's extra data mechanism.
//
// By default, flex considers extra data to be a void* that should be
// type-cast as required. However, we can use this macro to redefine the
// extra data's type so as to avoid unnecessary casting.
#define YY_EXTRA_TYPE lobot::TTIMap*

// When no rules match, flex's default action is to echo the input to
// stdout. This can be quite annoying when we would like our program to
// go about its work with minimal chatter.
//
// One way to suppress the echo action is to define a fallback rule at
// the end of the rules section that applies when none of the other match
// and have an empty action. However, for some strange reason, this does
// not always work.
//
// As a workaround, we define the ECHO macro used by flex to be empty.
// This seems to work fine.
#define ECHO

%}

/*
   These states are used by the scanner while parsing individual records
   in the metlogs.
*/
%x LOBAY_PARSE_RECORD LOBAY_READ_NUMBER

/*
   Since this scanner will be used to parse multiple log files in
   parallel, we need it to be reentrant to ensure that it works properly
   in a multithreaded environment.
*/
%option reentrant

/*
   The scanner is used to parse metrics logs stored on disk. It will
   never be used interactively by end users.
*/
%option batch never-interactive

/*
   The lobay program uses another lex-based scanner for tokenizing the
   config file. To ensure this one doesn't clash with that, we change the
   default function prefixes from "yy" to the following.
*/
%option prefix="lobay_parser_"

/*
   Even though lex generates C code, this scanner is actually part of a
   C++ program. Therefore, we might as well have it generate the code in
   a file that the compiler and build system will readily recognize as
   C++. Furthermore, because of the way the INVT automatic dependency
   calculator works, we also need a corresponding header file that we can
   include in the client module's C++ source file to get the final link
   step to work properly.

   DEVNOTE: The build takes place in the saliency root directory.
   Consequently, we must specify the full pathname relative to that
   directory to get flex to send the C source and header files to the
   proper location under the Robolocust root. If we were to use only the
   base file names, e.g., LoBaylogParser.C, the output would end up in
   the saliency root directory and would not be found by the other
   Robolocust modules that depend on this parser.
*/
%option outfile="src/Robots/LoBot/baylog/LoBaylogParser.C"
%option header-file="src/Robots/LoBot/baylog/LoBaylogParser.H"

/*
   For this parser to work properly, we need to be able to stack the
   start states.
*/
%option stack

/*
   Instruct flex to suppress unnecessary functions so that we don't get
   any warnings (which can be show stoppers no thanks to INVT's use of
   -Werror in its build system).
*/
%option noyywrap nounput noyy_top_state

/*----------------------------- LEX RULES -----------------------------*/

%%

%{
// Each entry in a Bayesian time-to-impact prediction experiment's log
// spans several lines with each line containing one piece of relevant
// information. We are only interested in some of these pieces of
// information. As we parse an entry, we store the differents pieces of
// information in these local variables. Then, once the entire log entry
// has been parsed, we will "send" the information stored in these locals
// to the lobot::TTIMap object specified by lobot::BaylogAnalyzer.
//
// DEVNOTE: These variables are local to the yylex() function generated
// by flex and are defined at the beginning of that function.
float lobay_lgmd_spike_rate = 0,
      lobay_actual_tti      = 0,
      lobay_predicted_tti   = 0,
      lobay_confidence      = 0;

// The informational lines making up a single log entry all follow the
// same format, viz., an informational string followed by an equals sign
// followed by a floating point number.
//
// To keep the parser's state machine simple, we use the following
// pointer to keep track of which of the above variables should "receive"
// the number in the informational line currently being parsed.
float* lobay_target = 0 ;
%}

   /*
      This rule recognizes the start of a multi-line log entry. Each such
      entry begins with a time-stamp (expressed as the number of
      milliseconds since the Unix epoch). After that comes an
      informational string spit out by the lgmd_extricate_tti behaviour.
      We don't really care much for this line except that it acts as a
      marker for the parser's internal state machine.
   */
^[[:digit:]]+" lgmd_extricate_tti  TTI estimator info:" {
      BEGIN(LOBAY_PARSE_RECORD) ;
   }

   /*
      These rules extract the numbers from the informational lines of a
      multi-line log entry and store them in the appropriate variable.
   */
<LOBAY_PARSE_RECORD>"LGMD spike rate" {
      lobay_target = &lobay_lgmd_spike_rate ;
      yy_push_state(LOBAY_READ_NUMBER, yyscanner) ;
   }

<LOBAY_PARSE_RECORD>"actual time-to-impact" {
      lobay_target = &lobay_actual_tti ;
      yy_push_state(LOBAY_READ_NUMBER, yyscanner) ;
   }

<LOBAY_PARSE_RECORD>"predicted time-to-impact" {
      lobay_target = &lobay_predicted_tti ;
      yy_push_state(LOBAY_READ_NUMBER, yyscanner) ;
   }

<LOBAY_PARSE_RECORD>"prediction confidence" {
      lobay_target = &lobay_confidence ;
      yy_push_state(LOBAY_READ_NUMBER, yyscanner) ;
   }

   /*
      This rule wraps up the parsing of a multi-line log entry and sends
      the information stored temporarily in the local variables to the
      lobot::TTIMap object being used to collect the various statistics
      of interest.
   */
<LOBAY_PARSE_RECORD>[^\\]$ {
      yyextra->add(lobay_actual_tti, lobay_lgmd_spike_rate,
                   lobay_predicted_tti, lobay_confidence) ;
      BEGIN(INITIAL) ;
   }

   /* Ignore everything else when we are parsing a record... */
<LOBAY_PARSE_RECORD>. {/* ignore */}

   /*
      These rules will read a floating point number, store it in the
      current target variable, and then return to the previous state.
   */
<LOBAY_READ_NUMBER>[-+]?[[:digit:]]+(\.[[:digit:]]*)? {
      *lobay_target = lobot::from_string<float>(yytext) ;
      yy_pop_state(yyscanner) ;
   }

<LOBAY_READ_NUMBER>. {/* ignore everything that doesn't look like a number */}
