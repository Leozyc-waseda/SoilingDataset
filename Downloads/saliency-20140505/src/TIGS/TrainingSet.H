/*!@file TIGS/TrainingSet.H Manage a paired set of eye position data and input feature vectors */

// //////////////////////////////////////////////////////////////////// //
// The iLab Neuromorphic Vision C++ Toolkit - Copyright (C) 2000-2005   //
// by the University of Southern California (USC) and the iLab at USC.  //
// See http://iLab.usc.edu for information about this project.          //
// //////////////////////////////////////////////////////////////////// //
// Major portions of the iLab Neuromorphic Vision Toolkit are protected //
// under the U.S. patent ``Computation of Intrinsic Perceptual Saliency //
// in Visual Environments, and Applications'' by Christof Koch and      //
// Laurent Itti, California Institute of Technology, 2001 (patent       //
// pending; application number 09/912,225 filed July 23, 2001; see      //
// http://pair.uspto.gov/cgi-bin/final/home.pl for current status).     //
// //////////////////////////////////////////////////////////////////// //
// This file is part of the iLab Neuromorphic Vision C++ Toolkit.       //
//                                                                      //
// The iLab Neuromorphic Vision C++ Toolkit is free software; you can   //
// redistribute it and/or modify it under the terms of the GNU General  //
// Public License as published by the Free Software Foundation; either  //
// version 2 of the License, or (at your option) any later version.     //
//                                                                      //
// The iLab Neuromorphic Vision C++ Toolkit is distributed in the hope  //
// that it will be useful, but WITHOUT ANY WARRANTY; without even the   //
// implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR      //
// PURPOSE.  See the GNU General Public License for more details.       //
//                                                                      //
// You should have received a copy of the GNU General Public License    //
// along with the iLab Neuromorphic Vision C++ Toolkit; if not, write   //
// to the Free Software Foundation, Inc., 59 Temple Place, Suite 330,   //
// Boston, MA 02111-1307 USA.                                           //
// //////////////////////////////////////////////////////////////////// //
//
// Primary maintainer for this file: Rob Peters <rjpeters at usc dot edu>
// $HeadURL: svn://isvn.usc.edu/software/invt/trunk/saliency/src/TIGS/TrainingSet.H $
// $Id: TrainingSet.H 9412 2008-03-10 23:10:15Z farhan $
//

#ifndef TIGS_TRAININGSET_H_DEFINED
#define TIGS_TRAININGSET_H_DEFINED

#include "Component/ModelComponent.H"
#include "Component/ModelParam.H"
#include "Image/Image.H"

#include <vector>

/// Manage a paired set of eye position data and input feature vectors
class TrainingSet : public ModelComponent
{
public:
  TrainingSet(OptionManager& mgr, const std::string& fx_type);

  Dims scaledInputDims() const;

  size_t numPositions() const;

  int p2p(const int i, const int j) const;

  int p2p(const Point2D<int>& p) const;

  Image<float> recordSample(const Point2D<int>& loc,
                            const Image<float>& features);

  /// Load feature and position vectors from a pair of .pfm files (such as those produced by save())
  /** <pfx>-features.pfm should contain the features associated with a
      series of frames, with nrows=NFRAMES and ncols=NFEATURES where
      NFEATURES is the number of features in the feature vector
      generated by whichever feature extractor produced this training
      set

      <pfx>-positions.pfm should contain the eye position vectors
      associated with the same series of frames, with nrows=NFRAMES
      and ncols=W*H where W*H is the number of pixels in each image of
      the frame sequence
   */
  void load(const std::string& pfx);

  /// Like load(), but rebalance the training set so that eye positions are included equally often
  void loadRebalanced(const std::string& pfx);

  void save(const std::string& pfx);

  Image<float> getFeatures() const;

  Image<float> getPositions() const;

  uint inputReduction() const;

  const std::string& fxType() const;

private:
  struct PosGroup
  {
    PosGroup(int nrow, int nfeat, int npos)
      :
      features(nrow, Image<float>(nfeat, 1, ZEROS)),
      positions(nrow, Image<float>(npos, 1, ZEROS)),
      counts(nrow, int(0)),
      totalcount(0),
      next(0)
    {}

    void add(const float* feat, const float* pos)
    {
      for (int i = 0; i < features[next].getWidth(); ++i)
        features[next][i] += feat[i];

      for (int i = 0; i < positions[next].getWidth(); ++i)
        positions[next][i] += pos[i];

      ++(counts[next]);
      ++totalcount;
      ++next;
      if (next == counts.size())
        next = 0;
    }

    std::vector<Image<float> > features;
    std::vector<Image<float> > positions;
    std::vector<uint> counts;
    uint totalcount;
    uint next;
  };

  OModelParam<Dims>     itsRawInputDims;
  OModelParam<bool>     itsDoRebalance;
  OModelParam<uint>     itsRebalanceThresh;
  OModelParam<uint>     itsRebalanceGroupSize;
  std::string  const    itsFxType;
  unsigned int const    itsReduction;
  size_t                itsNumFeatures;
  bool                  itsLocked;
  std::vector<float>    itsFeatureVec;
  std::vector<float>    itsPositionVec;
  std::vector<PosGroup> itsPosGroups;
  int                   itsNumTraining;
  int                   itsNumLoaded;
  mutable Image<float>  itsFeatures;
  mutable Image<float>  itsPositions;

  OModelParam<int>      itsDecimationFactor;
};

// ######################################################################
/* So things look consistent in everyone's emacs... */
/* Local Variables: */
/* mode: c++ */
/* indent-tabs-mode: nil */
/* End: */

#endif // TIGS_TRAININGSET_H_DEFINED
